{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TxMM_Assignment1_final_student",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IWUfTDvUelh",
        "colab_type": "text"
      },
      "source": [
        "# TxMM 2019/20\n",
        "## Assignment 1: Preprocessing & NLP\n",
        "\n",
        "Imagine you have a scientific interest in what people dream about. What are frequent motifs and how common might they be? Many of us have probably dreamed about falling from great heights or socially embarassing situations, but which is more common?\n",
        "\n",
        "To find out, we could recruit a number of volunteers and ask them to keep a dream journal. This would give us a small reliable sample of dream reports. As an alternative to gather much more data, we can try tapping a source of information that's close to lots of people, namely their Twitter feeds. \n",
        "\n",
        "As a researcher you must be aware that your data sample choice is not a representative reflection of actual dream behavior in general. The scope of your study is limited by several biases (in this case: limited to people who are on Twitter, only those dreams they are willing to share; they do not tweet exhaustively, but tweet when they have the time).\n",
        "\n",
        "In this study we try to answer the following research question:\n",
        "What are the dream themes most frequently described on Twitter?\n",
        "\n",
        "Learning goals of this assignment:\n",
        "\n",
        "- Get hands-on experience with text preprocessing and the characteristics of textual data\n",
        "- Learn that cleaning and filtering of textual data is not a simple or trivial task\n",
        "- Learn to convert a reseach question to a set of steps to find an answer to the question\n",
        "- Learn that looking at and into your data set in essential to grasp whether your data set is actually suited to answer your research question\n",
        "- Get acquainted with some tools for natural language processing (NLP)\n",
        "\n",
        "\n",
        "Whenever you get stuck during the assignment or have some conceptual questions, you can simply talk to the TAs or send a mail to Justine (j.winkler@student.ru.nl) or Klaus (k.lux@student.ru.nl) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRcqcZgfWDsi",
        "colab_type": "text"
      },
      "source": [
        "Most of you will have worked with Python notebooks before, but for some, this might be entirely new. Here is a brief introduction on how they work. You can skip this section if you feel confident in your knowledge of notebooks.\n",
        "\n",
        "## Brief notebook tutorial\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDaffl9-Gh4n",
        "colab_type": "text"
      },
      "source": [
        "### Starting a notebook server\n",
        "\n",
        "The easiest way to run a notebook is to upload the notebook file to a service such as [Google Colab](https://colab.research.google.com) or [Kaggle](https://www.kaggle.com/kernels). These sites offer free computational resources that you can use to run notebooks and a relatively hassle-free, as you don't have to install Python, Jupyter or any supporting libraries.\n",
        "\n",
        "If you would like to run the notebook on your own machine instead, you can follow the tutorial [here](https://jupyter.readthedocs.io/en/latest/install.html). \n",
        "\n",
        "### Running the notebook\n",
        "\n",
        "Once you have your notebook server running (either on a website or locally), you can start executing code. Notebooks are great in cases where you want to interleave code and text, e.g. when you want to perform a data analysis and provide some commentary of the findings along the side. They are not so great for production-level systems, e.g. when you work for a company and are tasked with designing a component to perform some textual analytics task. For these purposes, scripts should be used. In later assignments, we'll also use those, but for now, notebooks are ideal. With growing experience, you'll get a feeling for when each tool is appropriate.\n",
        "\n",
        "Notebooks distinguish between code cells and text cells. Code cells may contain arbritrary Python code. They can be executed in arbritary order. Text cells contain markup. When executed, they will change and show the formatted output of the markup. In this assignment, use code cells to perform text mining tasks and text cells to comment on findings or answer questions we ask you. To get you started, here's a simple question. Answer every questions marked with a **Q** directly in the same cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5uPE7lX_Ele",
        "colab_type": "text"
      },
      "source": [
        "**Q:** What cell types can you find in a notebook?\n",
        "\n",
        "**A:** *Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWKzKuVrAA-g",
        "colab_type": "text"
      },
      "source": [
        "The following code cell contains a simple print statement. The output of all the statements will be shown below the cell that produced them, so the string will be printed below the following cell. Run the cell, then maybe change one or two of the variables to see the effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMoJv3An8d9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "course_name = 'TxMM'\n",
        "course_year = 2019\n",
        "\n",
        "print(f'Welcome to {course_name}, {course_year} edition!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQ7PALiBE-c",
        "colab_type": "text"
      },
      "source": [
        "An important thing to keep in mind is that variables that you declare in one cell stay in memory once it has been executed. This is a powerful tool, as it allows you to refer back to variables you've already computed and to effectively split your task in managable chunks. Like every powerful tool, it also involves complexity: Make sure to execute cells in the correct order because otherwise, variables might not have their intended values when a cell refers to them. Even worse, they might not even be instantiated, giving rise to an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtOvSrfjBpNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Next year we\\'ll welcome students for {course_name}, {course_year + 1} edition.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzPpZ28IB-cc",
        "colab_type": "text"
      },
      "source": [
        "Try changing one of the variables above without running the cell where they are declared. You'll notice that when you run the second code cell, the values won't get updated.\n",
        "\n",
        "### Importing and installing packages\n",
        "Notebooks rely on a *kernel* or *runtime* to execute Python code. This is a separate Python process. When a call to a function crashes, you might get a message about the kernel having died. Sometimes, you might also need to manually restart the kernel. As with every Python process, this one comes with a number of pre-installed packages, such as *os* for system calls to for example read files or *re* for regular expressions. Importing these packages is easy and works just like in normal scripts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i45LT9EACwh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the system library\n",
        "import re\n",
        "\n",
        "input_string = 'TxMM is good fun.'\n",
        "# use a function from the library\n",
        "match = re.search('fun', input_string)\n",
        "\n",
        "print(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XDpt05HFF3r",
        "colab_type": "text"
      },
      "source": [
        "In contrast, some packages might not be installed. In this assignment, we'll use some packages that you have to install yourself. In a normal Python environment, you can use *pip* to install packages on the command line. To do the same in a notebook, run the command in a code cell, but make sure to prepend it with an exclamation mark. This tells the kernel to hand this command to the system command line. See the following cell for an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l81AN4uSFvvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhpkQvyCnNet",
        "colab_type": "text"
      },
      "source": [
        "If the package was installed in the first place, the output will read *Requirement already satisfied*, otherwise, you should get a message informing about the successful installation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5d1PkrXFxvK",
        "colab_type": "text"
      },
      "source": [
        "These are the most important things you need to know about notebooks. We'd recommend you to just get started now, but if you run into any trouble, you can check out the following [blogpost](https://www.dataquest.io/blog/jupyter-notebook-tutorial/). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK6STTYHG0DR",
        "colab_type": "text"
      },
      "source": [
        "## Loading data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqHcfA5zG5Zz",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, we'll look at collection of roughly 96,000 tweets crawled from the Twitter API between June and August 2014. Each of the tweets contains the phrase *I dreamed* or the phrase *I have dreamt*. Rather than storing each tweet in a separate file, all tweets have been dumped to a single file. Each line corresponds to a single tweet. For each tweet, the following information is stored:\n",
        "\n",
        "*   **phrase**: The query phrase that matched the tweet\n",
        "*   **id**: A unique id\n",
        "*   **username**: The name of the user that sent the tweet\n",
        "*   **time**: the exact time the tweet was sent\n",
        "*   **tweet_text**: The actual text that was sent\n",
        "\n",
        "Individual chunks of information are separated by a tab character. \n",
        "\n",
        "First, we'll need to define a function that iterates over the whole file line by line, splits the line into chunks and then returns a list of parsed tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZH6V_dYCrn3",
        "colab_type": "text"
      },
      "source": [
        "Task 1: Implement the function below. It takes a path as its arguments and returns a list of lists. Each tweet is a list of the chunks we found in the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jArD7d29ICiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hint: although usually an library call is good as the first start, try to only use inbuilt functions for this\n",
        "def load_data(data_path):\n",
        "  tweets = None # TODO: Replace!\n",
        "  return tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCVzCkEZMzhH",
        "colab_type": "text"
      },
      "source": [
        "Let's load the data and briefly inspect it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sXjHXSor-_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_data = 'tweets_clean.txt'\n",
        "tweets = load_data(path_to_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr21C4W1sC1I",
        "colab_type": "text"
      },
      "source": [
        "The following cell contains some assert statements. They check if a condition hold and print a string if otherwise. If there's no output after running the cell, your function should have worked correctly. If not, use the string output to find out what is wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcwFNWbuMmKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(tweets) == 96118,'Not all tweets were loaded.'\n",
        "assert isinstance(tweets[0],list),'Every tweet should be a list of elements.'\n",
        "assert len(tweets[0]) == 5, 'Every tweet should contain exactly five elements.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4lBJEyjsAoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print some tweets\n",
        "print(tweets[65])\n",
        "print(tweets[12])\n",
        "print(tweets[13322])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z8mMi33PHVI",
        "colab_type": "text"
      },
      "source": [
        "Having the tweets as a list of lists is possible, but doesn't allow us to sort or filter them easily. We can use a package called pandas to make this task easier: Our collection of tweets becomes a *DataFrame* object, which is essentially just a big table. Each of the tweets is a row in the table, whereas each of the individual information chunks becomes a column. Later on, we'll see why this is useful. First, we'll install and import pandas and then load the tweets into a DataFrame object.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El5pkifgPwB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pandas\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rItwHhXzUcs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = ['phrase', 'id', 'username', 'time', 'tweet_text']\n",
        "tweets = pd.DataFrame(tweets, columns = names)\n",
        "# this line parses the time stamp strings to date objects we can sort on\n",
        "tweets['time'] =  pd.to_datetime(tweets['time'])\n",
        "# sort on the date and reset the index\n",
        "tweets = tweets.sort_values('time')\n",
        "tweets = tweets.reset_index(drop=True)\n",
        "\n",
        "print(tweets.shape)\n",
        "print(tweets.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwz4R2VvgRNw",
        "colab_type": "text"
      },
      "source": [
        "## Text analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqdZefuIWSRV",
        "colab_type": "text"
      },
      "source": [
        "Let's first get an overview of the dataset. There's a lot of tweets in there, but we don't know how many of them contain genuine descriptions of dreams. To take a dive and inspect a number of tweets in an easy manner, an interactive scatter plot is the right tool. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLEbjIrajcVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute a new column (or Series) by using the map function on an existing column\n",
        "# each element in tweet_text gets fed to the len function \n",
        "# the results get stored in the new column\n",
        "tweets['length'] = tweets.tweet_text.map(len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSCC8NILsYy1",
        "colab_type": "text"
      },
      "source": [
        "The following version installs a specific version of the plotting library we want to use. If a previous version is already installed, it will get uninstalled automatically, but their might output asking you to restart the runtime / kernel. Do so via the menu above and then run the cells above again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz8yOQ-BEBuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you might have to restart your runtime after this line executes\n",
        "!pip install plotly=='4.0.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUoQL-6EYD2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "# plot some random 50 tweets, including their text in the hover field\n",
        "px.scatter(tweets[5000:5050],x='time',y='length',hover_data=['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip44rFI3oQ38",
        "colab_type": "text"
      },
      "source": [
        "Q1: Look at the 50 tweets in the plot, reading their content as you hover over them. Roughly, what percentage of those are genuine descriptions of what people dreamed in on of the previous nights? Of those that don't fit that description, can you identify what is going on in them? What do people intend with some of them?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yHPaaKJQd36",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMak5HnBQip3",
        "colab_type": "text"
      },
      "source": [
        "Unfortunately, the world is a messy place. Data is hardly ever ready for analysis or model-training, but instead requires manual cleaning. In this section of the assignment, we'll take some steps specifically needed for social media analysis.\n",
        "\n",
        "As we are interested in those tweets that contain actual dream descriptions, we aim to filter out duplicates and retweets as they are not expressing personal dream experiences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM7JHGRZUmmZ",
        "colab_type": "text"
      },
      "source": [
        "### Finding retweets\n",
        "\n",
        "In the export format, retweets always start with 'RT', followed by a space. \n",
        "\n",
        "Task 2: Change the function stub below to capture retweets so they can be removed. The function takes a string and should return a boolean that indicates whether the string is a retweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VV0YGZ6QhPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function that indicates whether a string is a retweet\n",
        "def isRetweet(string):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdOSW1OpEcXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_1 = isRetweet('RT @tester this is a test!')\n",
        "assert test_1 == True, 'Your function missed a retweet!'\n",
        "test_2 = isRetweet('We render everything in RT, that is real-time!')\n",
        "assert test_2 == False, 'Your function spotted a RT in error.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV03OI3DFGZi",
        "colab_type": "text"
      },
      "source": [
        "Task 3: Now, change the code below to apply the function to the tweet_text and store the results in the new column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w257Y47KVf6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweets['is_retweet'] = YOUR_CODE_HERE\n",
        "\n",
        "n_retweets = sum(tweets.is_retweet)\n",
        "\n",
        "assert n_retweets == 20132, f'Your function stopped {n_retweets}, it should have spotted 20132.'\n",
        "\n",
        "tweets.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soxHPdbbV9vn",
        "colab_type": "text"
      },
      "source": [
        "### Finding duplicate tweets\n",
        "\n",
        "Certain users might tweet the same statement over and over. Let's remove these tweets too. We'll make a new column called 'is_duplicate' that contains a boolean that indicates whether a tweet is a duplicate.\n",
        "\n",
        "Task 4: Complete the code below, using the right function from the pandas API. Two tweets should be considered duplicates if their tweet_text fields are identical. All other fields should be disregarded. Pass the parameter to the function to not mark the first occurence as a duplicate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh51Bru_V1hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop duplicate tweets\n",
        "\n",
        "# tweets['is_duplicate'] = YOUR_CODE_HERE\n",
        "n_duplicates = sum(tweets.is_duplicate)\n",
        "\n",
        "assert n_duplicates == 17717, f'Your function spotted {n_duplicates}, it should have spotted 17717.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCs2ZveuH6jg",
        "colab_type": "text"
      },
      "source": [
        "We can see the results of the cleanup after you run the following cell. The scatter plot now shows which tweets out of our sample we removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x62pN3s2dqOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this line combines the two columns into a new one using binary operators\n",
        "# ~ is not, | is or --> keep everything that is not a retweet or a duplicate\n",
        "tweets['to_keep'] = ~ (tweets.is_retweet | tweets.is_duplicate)\n",
        "\n",
        "# hack because plotly has a bug for using bools as coloring attribute\n",
        "tweets['to_keep_str'] = tweets['to_keep'].astype(str)\n",
        "\n",
        "px.scatter(tweets[5000:5050],x='time',y='length',color='to_keep_str',hover_data=['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LDd6wchXUBK",
        "colab_type": "text"
      },
      "source": [
        "### Removing spam accounts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEKpYCfBX6WF",
        "colab_type": "text"
      },
      "source": [
        "Let's look at how often people tweeted tweets containing our query phrases over the duration of crawling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsWVMjejWgKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This command counts how often a particular value appears in the column of the dataframe\n",
        "# In this case, we ask how often each username appears\n",
        "counts = tweets.username.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4SvqQWbfLuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "count_list = list(counts)\n",
        "plt.plot(count_list)\n",
        "plt.xlabel('User')\n",
        "plt.ylabel('Number of tweets')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8oGkOmKYKXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(count_list, log=True, bins=100)\n",
        "plt.xlabel('Number of tweets')\n",
        "plt.ylabel('Number of users')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GCRgDCffXl",
        "colab_type": "text"
      },
      "source": [
        "Looks like there are some people who tweeted the phrase a lot! What do they actually tweet about?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vbzVj6beF9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List the 10 most frequent usernames\n",
        "print(counts.nlargest(10))\n",
        "\n",
        "# Print some of the tweets of each of the 5 most frequent usernames\n",
        "most_frequent = counts.nlargest(5).to_dict()\n",
        "# for each username in the set\n",
        "for name in most_frequent.keys():\n",
        "  # get a sample of the associated tweets and print\n",
        "  sample = tweets[tweets.username == name].tweet_text.sample(5)\n",
        "  print(name)\n",
        "  print(sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8d5Fsn-gxUo",
        "colab_type": "text"
      },
      "source": [
        "Now, where to go from here? Should we drop all these tweets because they're spam? Maybe we should only drop some, based also on what the actual content of the tweets is? Questions like these usually don't have an easy, clear-cut answer. Depending on your research question, you might decide to drop them, especially if you're trying to infer some more general facts about all the people that use Twitter. In contrast, if your analysis is on the level of individual users, finding that they engage in this behaviour might be highly valuable information.\n",
        "\n",
        "For this small study we want to remove all tweets from users who tweeted more than twice in our sample.\n",
        "\n",
        "Task 5: First, make a list of all accounts who tweeted more than twice. Then, using that list, complete the cell below to make a column that identifies tweets from spam accounts. Hint: *Use the isin function from the pandas api on the correct column*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on4oVWBJJanc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 2\n",
        "# get a list of usernames of all people who exceed the threshold\n",
        "# YOUR_CODE_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrt0rSH6gs1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mark their tweets\n",
        "# tweets['is_from_spammer'] = YOUR_CODE_HERE\n",
        "\n",
        "n_spam_tweets = sum(tweets.is_from_spammer)\n",
        "assert n_spam_tweets == 15083, f'Your function spotted {n_spam_tweets}, it should have spotted 15083.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ZkL8BlJrwD",
        "colab_type": "text"
      },
      "source": [
        "Let's plot our fifty tweets again, this time also flagging up spam tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czEJtIXTrB_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets['to_keep'] = ~ (tweets.is_retweet | tweets.is_duplicate | tweets.is_from_spammer)\n",
        "\n",
        "# hack because plotly has a bug for using bools as coloring attribute\n",
        "tweets['to_keep_str'] = tweets['to_keep'].astype(str)\n",
        "\n",
        "px.scatter(tweets[5000:5050],x='time',y='length',color='to_keep_str',hover_data=['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd_xyhtTqpMU",
        "colab_type": "text"
      },
      "source": [
        "Q2: Now after the cleanup, look at the fifty tweets again. Did we manage to increase the percentage of tweets that contain a genuine dream description? What problems still remain?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBPUajKV3r9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# actually drop these instances now\n",
        "tweets = tweets[tweets.to_keep]\n",
        "print(tweets.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlQpblBrXmeM",
        "colab_type": "text"
      },
      "source": [
        "### Changing tweet formatting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Gcm-jaX86D",
        "colab_type": "text"
      },
      "source": [
        "Let's try and eliminate some of the variation in the tweets that we're not interested in. We'll define functions for replacing usernames, hashtags and links with generic tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhX9KaPkXtgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "# uses a regex to detect usernames and replaces them by USERNAME\n",
        "def replace_username(in_string):\n",
        "    return re.sub('@(\\w){1,15}','USERNAME',in_string)\n",
        "# uses a regex to detect hashtags and replaces them by HASHTAG\n",
        "def replace_hashtag(in_string):\n",
        "    return re.sub('#(\\w)*','HASHTAG',in_string)\n",
        "# uses a regex to detect links and replaces them by LINK  \n",
        "def replace_link(in_string):\n",
        "    return re.sub('(http:)?//t.co/\\w*', 'LINK',in_string)\n",
        "\n",
        "# map the text to itself, applying each of the functions\n",
        "tweets.tweet_text = tweets.tweet_text.map(replace_username)\n",
        "tweets.tweet_text = tweets.tweet_text.map(replace_hashtag)\n",
        "tweets.tweet_text = tweets.tweet_text.map(replace_link)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8tke0WibkJM",
        "colab_type": "text"
      },
      "source": [
        "Now, let's also remove everything that has a link in it. We'll assume a genuine dream description does not contain a link. \n",
        "\n",
        "Task 6: Make a function that returns true if the new LINK token is in a tweet, then add a new column 'has_link' to the data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYK4-JTDKgLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function that indicates whether a string is a retweet\n",
        "def hasLink(string):\n",
        "    pass\n",
        "  \n",
        "# tweets['has_link'] = YOUR_CODE_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1hEQCozKv4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_tweets_with_link = sum(tweets.has_link)\n",
        "assert n_tweets_with_link == 5539, f'Your function spotted {n_tweets_with_link}, it should have spotted 5539.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT6gYRCdQ6hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop the tweets\n",
        "tweets = tweets[~tweets.has_link]\n",
        "print(len(tweets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNnII4JcKzOx",
        "colab_type": "text"
      },
      "source": [
        "If everything went correctly up to here, you'll notice we've dropped close to half of our original tweets! Data cleaning often takes a heavy toll. Now, let's look into the actual text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvpDav2CgUc1",
        "colab_type": "text"
      },
      "source": [
        "## Text analysis\n",
        "\n",
        "What dreams do people describe in their tweets? \n",
        "\n",
        "Maybe we should first look at what words are frequent to appear in the tweets? For this purpose, we'll need to split them into lists of tokens. A token is a string of characters separated by white space. We thus need to perform tokenization, i.e. we need to split punctuation marks from words.\n",
        "\n",
        "NLTK has a variety of tokenizers. The most commonly used tokenizers is just a function from the base package called *word_tokenize*. However, there is also a tokenizer specifically for tweets, called the tweet tokenizer.\n",
        "\n",
        "This tokenizer has three parameters. For each of them, by means of varying the *sample_sentence* and by checking the documentation, find out what it does.\n",
        "\n",
        "Q3: What is the effect of the three parameters of the TweetTokenizer?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj2r4cLrjGHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import download, FreqDist\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "# downloading this NLTK data might take a while depending on your connection\n",
        "download('punkt')\n",
        "download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPTfwnvzuSvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sentence = 'We\\'ll need to split them into lists of tokens. And then some more.'\n",
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles= True)\n",
        "token_list = tokenizer.tokenize(sample_sentence)\n",
        "print(token_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxgr9T1acEQJ",
        "colab_type": "text"
      },
      "source": [
        "Now, let's look at the distribution of tokens in the sentence. We'll use the FreqDist class for this. \n",
        "\n",
        "Q4: What does the invoking the FreqDist result in?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDLBgKuucCHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_dist = FreqDist(token_list)\n",
        "freq_dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNLrE3xl03Zr",
        "colab_type": "text"
      },
      "source": [
        "Let's try to only look at a window of words following the query phrase. We made a function for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE-fMp0az2RU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_following_tokens(tweet):\n",
        "  phrase = tweet.phrase\n",
        "\n",
        "  parts = tweet.tweet_text.lower().split(phrase.lower())\n",
        "  words_after = parts[-1]\n",
        "  \n",
        "  token_list = tokenizer.tokenize(words_after)\n",
        "  \n",
        "  return token_list\n",
        "\n",
        "tweets['immediately_after'] = tweets.apply(find_following_tokens, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrutqgUmOcbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets['immediately_after'].sample(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj3-58GWceUY",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the distribution of words in this window for every tweet. Run the following two cells to get a glimpse of the distribution in a plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDJhNySjXVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "pool = Pool(cpu_count())\n",
        "out = pool.map(FreqDist, tweets.immediately_after.to_list())\n",
        "pool.close()\n",
        "\n",
        "word_dist = FreqDist()\n",
        "for dist in out:\n",
        "  word_dist.update(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUejichzxXPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_freqs = sorted(word_dist.values(),reverse=True)\n",
        "plt.plot(word_freqs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuQ8XgDt4YLB",
        "colab_type": "text"
      },
      "source": [
        "Q5: How should the x and the y axis be labelled? What pattern can you see in the plot? Referring back to the lecture slides, do you know a name for this phenomenon?\n",
        "\n",
        "A: *your answer here*\n",
        "\n",
        "Now, let's look at some of the words to see if we can identify any patterns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5T0HaEj8Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dist.most_common(25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws3_eujEyqp-",
        "colab_type": "text"
      },
      "source": [
        "Nothing to remarkable, right?\n",
        "\n",
        "Instead of only looking at single words at a time, let's try looking at longer strings of words. Below, we have specified a function for your convenience. It extracts n-grams, sequences of n adjacent words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ECfPERZBETr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def extract_ngram_freqs(token_list, n):\n",
        "  grams = list(ngrams(token_list, n))\n",
        "  cleaned_grams = []\n",
        "  for word_tuple in grams:\n",
        "      for word in word_tuple:\n",
        "          if word not in stopwords:\n",
        "              cleaned_grams.append(word_tuple)\n",
        "              break\n",
        "  \n",
        "  return cleaned_grams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLLX7sfDY5Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_ngram_freqs(['I', 'dreamed', 'about', 'you'], n=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQPUmTFmYzja",
        "colab_type": "text"
      },
      "source": [
        "Q6: Run the cell above and vary the parameters of the function call, i.e. by feeding in another short sentence in the same format or by changing n. What does the function do? What exactly is extracted and what is omitted?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnHk5HpgZMgG",
        "colab_type": "text"
      },
      "source": [
        "To extract n-grams for a large number of tweets, we've specified another function that uses multiprocessing. You don't need to understand its detailed workings, but you can treat it as a prototype in case you ever need to parallelise an extraction task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4pB_ajXDJgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Pool, cpu_count\n",
        "from functools import partial\n",
        "'''\n",
        "A function to extract ngrams for every tweet in a frame. \n",
        "If not present, adds a column with the list of n-grams to the frame.\n",
        "Its name is dependent on n.\n",
        "'''\n",
        "def extract_and_add_ngrams(frame, token_column, n):\n",
        "\n",
        "  pool = Pool(cpu_count())\n",
        "  extractor_func = partial(extract_ngram_freqs, n=n)\n",
        "  list_of_grams = pool.map(extractor_func, list(tweets.immediately_after))\n",
        "  pool.close()\n",
        "\n",
        "  # so grams1, grams2 and so on\n",
        "  name = 'grams' + str(n)\n",
        "  if name not in frame.columns:\n",
        "    tweets[name] = list_of_grams\n",
        "  return name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oJlS0YbZxNu",
        "colab_type": "text"
      },
      "source": [
        "Let's try and graphically inspect these n-grams. We'll download a package called wordcloud and then make some word clouds for different settings of n.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AjtzXFIR9vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdvnMtboZ_RL",
        "colab_type": "text"
      },
      "source": [
        "This is a helper function that takes care of the plotting. You don't need to understand what it does to proceed with the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oi_DfBD0lob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.probability import MLEProbDist\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_dist_as_cloud(word_dist):\n",
        "  prob_dist = MLEProbDist(word_dist)\n",
        "  viz_dict = {}\n",
        "  for word_tuple in word_dist:\n",
        "    string = ' '.join(word_tuple)\n",
        "    viz_dict[string] = prob_dist.prob(word_tuple)\n",
        "\n",
        "  cloud = WordCloud(width=1600,height=400).generate_from_frequencies(viz_dict)\n",
        "  \n",
        "  plt.figure(figsize = (25,25))\n",
        "  plt.imshow(cloud, interpolation='bilinear')\n",
        "\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy3xaIaUagHP",
        "colab_type": "text"
      },
      "source": [
        "The following cell extracts and plots n-grams. Vary the parameter, trying out some settings between say 1 and 5. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGnrWFRwJqRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vary this parameter\n",
        "n = 7\n",
        "# extracts the n-grams\n",
        "column_name = extract_and_add_ngrams(tweets,'immediately_after', n = n)\n",
        "\n",
        "word_dist = FreqDist()\n",
        "for grams in tweets[column_name]:\n",
        "  word_dist.update(FreqDist(grams))\n",
        "print(f'Found {len(word_dist)} unique n-grams for n = {n}')\n",
        "\n",
        "most_common = word_dist.most_common(25)\n",
        "for word_tuple in most_common:\n",
        "  print(word_tuple)\n",
        "# calls our helper function for plotting\n",
        "plot_dist_as_cloud(word_dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nStGzQ0xawdh",
        "colab_type": "text"
      },
      "source": [
        "Q7: What happens when you increase the size of n? Specifically, what happens to the number of n-grams and the occurence count of the most frequent n-gram?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI0ZCfzEdpii",
        "colab_type": "text"
      },
      "source": [
        "Both the most frequent word n-grams and the word cloud remarkably show that certain exact phrases are repeated by many users. We would not expect that users express their  personal dream experiences in the exact same words, and indeed these tweets do not express dreams but something else.\n",
        "\n",
        "Q8: So what is going on here? Why are people using the same phrase over and over?\n",
        "\n",
        "A: *Your answer here*\n",
        "\n",
        "Q9: Can you think of ways to remove these tweets from the sample ? (you do not need to code this solution, only reflect on the problem)\n",
        "\n",
        "A: *Your answer here*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFTV5IJENwY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "# give people the chance to try to find which tweets contain these grams\n",
        "\n",
        "def has_phrase(gram_list, phrase_tuple):\n",
        "  return str(phrase_tuple in gram_list)\n",
        "\n",
        "def search_for_phrase(frame, phrase):\n",
        "\n",
        "  phrase = phrase.lower()\n",
        "  phrase_parts = phrase.split(' ')\n",
        "  phrase_tuple = tuple(phrase_parts)\n",
        "  \n",
        "  search_func = partial(has_phrase,phrase_tuple=phrase_tuple)\n",
        "\n",
        "  search_field_name = 'grams' + str(len(phrase_tuple))\n",
        "  if search_field_name not in frame:\n",
        "     extract_and_add_ngrams(frame,'immediately_after',len(phrase_tuple))\n",
        "\n",
        "  search_frame = frame.copy()\n",
        "  search_frame['match'] = search_frame[search_field_name].apply(search_func)\n",
        "  return search_frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8tJp7X7kJPx",
        "colab_type": "text"
      },
      "source": [
        "Maybe one of those phrases has piqued your interest and you want to look at some of the tweets that contain it? In the following cell, you can swap out the contents of the phrase variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFDh5mMskC6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phrase = 'when i woke up'\n",
        "search_frame = search_for_phrase(tweets,phrase)\n",
        "px.scatter(search_frame,x='time',y='length',color='match',hover_data=['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "almbJsw9faTr",
        "colab_type": "text"
      },
      "source": [
        "Q10: Try searching for the phrase 'about you nearly every night'. Can you make a guess where people found the inspiration for that phrase?\n",
        "\n",
        "A: *Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXBH6gbJrV3N",
        "colab_type": "text"
      },
      "source": [
        "## Discussion ##\n",
        "\n",
        "Our starting point for this study was to investigate what the dream themes most frequently described on Twitter are. We inspected the data sample and attempted various cleaning steps.\n",
        "\n",
        "However: your inspection of the data has uncovered a huge problem with the sample as it turns out to be extremely difficult to separate genuine dream reports from other tweets that for some other reason contained the phrase 'I dreamed'. \n",
        "\n",
        "Q11: Do you think that the data sample we are using is actually suited to answer your research question 'What are the dream themes most frequently described on Twitter?'\n",
        "\n",
        "A:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_tBjGGeoGwK",
        "colab_type": "text"
      },
      "source": [
        "## Dream themes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRe4zy7nf_Rp",
        "colab_type": "text"
      },
      "source": [
        "So far, our bottom-up approach to dream data on Twitter has revealed little. Given the high number of tweets and the strong noise in the data, manual inspection for dominant topics is quite hard. We could try and ease this process, e.g. by attempting topic modelling or some dimensionality reduction technique, but these topics will only be discussed in the lectures over the coming weeks.\n",
        "\n",
        "For now, let's try another way. Let's make up an explicit hypothesis about what people dream about based on a [scientific study](https://dreams.ucsc.edu/Library/bulkeley_2010.html) of dream reports that counted how certain themes are mentioned in dream reports by simply counting words.\n",
        "\n",
        "Two common themes are flying and falling. We'll then try and separate our tweets based on whether they actually contain words associated with them. Let's see how frequent these themes really are in our Twitter sample!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVWsz4GLkUeV",
        "colab_type": "text"
      },
      "source": [
        "We made a dictionary whose keys represent the two themes. For each key, there is  a list of associated phrases as used in the study."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn2lYF8sEZjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dream_class_dict = {\n",
        "    'falling': ['falls','fell','falling','collapses','collapsed','collapsing','drops','dropped','dropping'],\n",
        "    'flying': ['fly','flies','flew','flying','floats','floated','floating','glides','gliding','glided']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br-0lVVtyfqu",
        "colab_type": "text"
      },
      "source": [
        "The following code cells extract the relevant word counts from the tweets and then classify each tweet based on the match with the word lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izZ9GGhVhVEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_dict = {}\n",
        "n_grams_needed = set()\n",
        "for dream_class in dream_class_dict.keys():\n",
        "    list_of_phrases = dream_class_dict[dream_class]\n",
        "    grams = []\n",
        "    for phrase in list_of_phrases:\n",
        "      phrase = phrase.lower()\n",
        "      words = phrase.split(' ')\n",
        "      gram_rep = tuple(words)\n",
        "      n_grams_needed.add(len(gram_rep))\n",
        "      grams.append(gram_rep)\n",
        "    new_dict[dream_class] = grams\n",
        "\n",
        "for n_gram in n_grams_needed:\n",
        "   list_name = 'grams' + str(n_gram)\n",
        "   if list_name not in tweets.columns:\n",
        "     extract_and_add_ngrams(tweets,'immediately_after',n_gram)\n",
        "\n",
        "dream_class_dict = new_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vh1QZpmhaWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Classify a tweet according to its dream class. Returns the class name of the best match.\n",
        "Unassigned is returned if no matching class was found.\n",
        "'''\n",
        "def classify_tweet(tweet):\n",
        "  class_scores = {}\n",
        "  for dream_class in dream_class_dict.keys():\n",
        "    gram_list = dream_class_dict[dream_class]\n",
        "    counter = 0  \n",
        "    for gram in gram_list:\n",
        "      # get the correct gram list for the lookup\n",
        "      list_name = 'grams' + str(len(gram))\n",
        "      grams_in_tweet = tweet[list_name]\n",
        "      if gram in grams_in_tweet:\n",
        "        counter = counter + 1 \n",
        "    class_scores[dream_class] = counter\n",
        "  \n",
        "  highest_score = 0\n",
        "  best = 'unassigned'\n",
        " \n",
        "  for class_name in class_scores.keys():\n",
        "    if class_scores[class_name] > highest_score:\n",
        "      highest_score = class_scores[class_name]\n",
        "      best = class_name\n",
        "  return best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7asLmoMyvjY",
        "colab_type": "text"
      },
      "source": [
        "Now, let's plot the tweets again, using the assigned classes as labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVTaNlGWRTAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_frame = tweets.copy()\n",
        "class_frame['class'] = tweets.apply(classify_tweet, axis=1)\n",
        "\n",
        "px.scatter(class_frame,x='time',y='length',color='class',hover_data=['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97laRNdyitx7",
        "colab_type": "text"
      },
      "source": [
        "Q12: In the Bulkeley & Domhoff study sourced above, falling dreams are reported twice as often as flying dreams. Is this the same in the Twitter sample?\n",
        "\n",
        "A: *Your answer here*\n",
        "\n",
        "Q13: What limitations do you see in this paradigm? Try to make sense of the classify_tweet function. How does it work? Do you see errors it makes? How could it be improved?\n",
        "\n",
        "A: *Your answer here*"
      ]
    }
  ]
}